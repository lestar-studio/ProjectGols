{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "938/938 [==============================] - 24s 25ms/step - loss: 1.2051 - accuracy: 0.5576 - val_loss: 0.7204 - val_accuracy: 0.7197\n",
      "Epoch 2/70\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.8311 - accuracy: 0.6996 - val_loss: 0.6352 - val_accuracy: 0.7527\n",
      "Epoch 3/70\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.7495 - accuracy: 0.7282 - val_loss: 0.5877 - val_accuracy: 0.7709\n",
      "Epoch 4/70\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.7028 - accuracy: 0.7467 - val_loss: 0.5602 - val_accuracy: 0.7876\n",
      "Epoch 5/70\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.6738 - accuracy: 0.7579 - val_loss: 0.5426 - val_accuracy: 0.7971\n",
      "Epoch 6/70\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.6433 - accuracy: 0.7678 - val_loss: 0.5128 - val_accuracy: 0.8066\n",
      "Epoch 7/70\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.6264 - accuracy: 0.7753 - val_loss: 0.5058 - val_accuracy: 0.8108\n",
      "Epoch 8/70\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 0.6117 - accuracy: 0.7806 - val_loss: 0.4940 - val_accuracy: 0.8239\n",
      "Epoch 9/70\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.5939 - accuracy: 0.7878 - val_loss: 0.4654 - val_accuracy: 0.8284\n",
      "Epoch 10/70\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.5774 - accuracy: 0.7959 - val_loss: 0.4733 - val_accuracy: 0.8283\n",
      "Epoch 11/70\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.5734 - accuracy: 0.7975 - val_loss: 0.4428 - val_accuracy: 0.8366\n",
      "Epoch 12/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.5578 - accuracy: 0.8049 - val_loss: 0.4366 - val_accuracy: 0.8397\n",
      "Epoch 13/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.5494 - accuracy: 0.8074 - val_loss: 0.4527 - val_accuracy: 0.8403\n",
      "Epoch 14/70\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.5442 - accuracy: 0.8108 - val_loss: 0.4581 - val_accuracy: 0.8299\n",
      "Epoch 15/70\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.5305 - accuracy: 0.8166 - val_loss: 0.4289 - val_accuracy: 0.8404\n",
      "Epoch 16/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.5257 - accuracy: 0.8172 - val_loss: 0.4066 - val_accuracy: 0.8506\n",
      "Epoch 17/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.5215 - accuracy: 0.8179 - val_loss: 0.4788 - val_accuracy: 0.8201\n",
      "Epoch 18/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.5173 - accuracy: 0.8208 - val_loss: 0.4052 - val_accuracy: 0.8531\n",
      "Epoch 19/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.5134 - accuracy: 0.8225 - val_loss: 0.4009 - val_accuracy: 0.8521\n",
      "Epoch 20/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.5073 - accuracy: 0.8225 - val_loss: 0.4025 - val_accuracy: 0.8545\n",
      "Epoch 21/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.4980 - accuracy: 0.8266 - val_loss: 0.4019 - val_accuracy: 0.8546\n",
      "Epoch 22/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.4996 - accuracy: 0.8267 - val_loss: 0.3983 - val_accuracy: 0.8573\n",
      "Epoch 23/70\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.4964 - accuracy: 0.8271 - val_loss: 0.4067 - val_accuracy: 0.8519\n",
      "Epoch 24/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.4976 - accuracy: 0.8273 - val_loss: 0.3900 - val_accuracy: 0.8590\n",
      "Epoch 25/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.4846 - accuracy: 0.8309 - val_loss: 0.3937 - val_accuracy: 0.8551\n",
      "Epoch 26/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.4836 - accuracy: 0.8324 - val_loss: 0.3816 - val_accuracy: 0.8644\n",
      "Epoch 27/70\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.4809 - accuracy: 0.8340 - val_loss: 0.3901 - val_accuracy: 0.8578\n",
      "Epoch 28/70\n",
      "938/938 [==============================] - 24s 25ms/step - loss: 0.4841 - accuracy: 0.8350 - val_loss: 0.3878 - val_accuracy: 0.8603\n",
      "Epoch 29/70\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.4853 - accuracy: 0.8330 - val_loss: 0.3832 - val_accuracy: 0.8613\n",
      "Epoch 30/70\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.4776 - accuracy: 0.8359 - val_loss: 0.4015 - val_accuracy: 0.8529\n",
      "Epoch 31/70\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.4770 - accuracy: 0.8374 - val_loss: 0.3837 - val_accuracy: 0.8642\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3816 - accuracy: 0.8644\n",
      "Test accuracy: 0.8644000291824341\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load Fashion MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # Added another convolutional layer\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),  # Increased units to 128\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),   # Added another fully connected layer\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', =5, restore_best_weights=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001),  # Lowered learning rate\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=15,  # Increased rotation range\n",
    "                             width_shift_range=0.15,  # Added width shift range\n",
    "                             height_shift_range=0.15,  # Added height shift range\n",
    "                             shear_range=0.15,  # Added shear range\n",
    "                             zoom_range=0.15,   # Added zoom range\n",
    "                             horizontal_flip=True) # Added horizontal flip\n",
    "datagen.fit(train_images) # Fit the data generator\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
    "                    epochs=70,  # Increased number of epochs\n",
    "                    validation_data=(test_images, test_labels), # Added validation data\n",
    "                    callbacks=[early_stopping]) # Added early stopping\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('Dataset/fashion_mnist_model_improved.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
